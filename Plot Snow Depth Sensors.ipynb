{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Process and Plot Judd snow sensor files\n",
    "\n",
    "This programm reads in CS data files from the four sites on Niwot Ridge as well as the two sites on Steamboat Mountain and the Jemez CZO site. It requires the modules listed below. They are standard with most Python installations. I suggest using the Anaconda installation if you need a place to start.\n",
    "\n",
    "## Just hit shift-enter to run through the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (22.0, 11.0) # plot size\n",
    "\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "myFmt = mdates.DateFormatter('%m/%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Locations and sensor numbers\n",
    "\n",
    "ALP: 11 sensors (1-10, 13)\n",
    "\n",
    "USA: 10 sensors\n",
    "\n",
    "LSA: 10 sensors \n",
    "\n",
    "AFX: 9? sensors\n",
    "\n",
    "PHQ: 6 sensors\n",
    "\n",
    "THD: 4 sensors\n",
    "\n",
    "JMZ: unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit the following cell to specify site, download date, and water year folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "site = 'USA' # name of the site\n",
    "filedate='20150803' # date of most recent file\n",
    "wypath = '2015' # set the water year\n",
    "plotpth = '/Users/barnhatb/Desktop/' # path where you want the plots\n",
    "# Output Data File:\n",
    "optdf = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You pretty much don't need to edit anything else past this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Files Found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141006.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141013.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141020.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141103.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141201.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141124.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141117.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141215.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141222.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150105.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20141229.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150112.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150126.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150119.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150202.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150216.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150301.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150309.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150316.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150330.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150323.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150406.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150420.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150413.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150427.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150504.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150518.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150511.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150525.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150601.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150608.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150615.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150622.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150629.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150713.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150706.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150720.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150803.dat',\n",
       " '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy2015/original_files/USA_20150727.dat']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if site == 'ALP': \n",
    "    sensors1 = 11\n",
    "    path = '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy'+wypath+'/original_files'\n",
    "    outpath = '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy'+wypath\n",
    "    files=glob.glob(path+'/'+site+'*.dat') # get all the files from one site\n",
    "    \n",
    "if site == 'USA':\n",
    "    sensors1 = 10\n",
    "    path = '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy'+wypath+'/original_files'\n",
    "    outpath = '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy'+wypath\n",
    "    files=glob.glob(path+'/'+site+'*.dat') # get all the files from one site\n",
    "    \n",
    "if site == 'LSA':\n",
    "    sensors1 = 10\n",
    "    path = '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy'+wypath+'/original_files'\n",
    "    outpath = '/Volumes/hydroProjects/Data/FieldData/pingersites/LTER/data/snow_sensor_data_files/wy'+wypath\n",
    "    files=glob.glob(path+'/'+site+'*.dat') # get all the files from one site\n",
    "    \n",
    "if site == 'PHQ':\n",
    "    sensors1 = 6\n",
    "    path = '/Volumes/hydroProjects/Data/FieldData/pingersites/Steamboat/data/wy'+wypath+'/PHQ/raw/'\n",
    "    outpath = '/Volumes/hydroProjects/Data/FieldData/pingersites/Steamboat/data/wy2014/PHQ'\n",
    "    site = 'PHQ2'\n",
    "    files=glob.glob(path+'/'+site+'_Table_*.dat') # get all the files from one site\n",
    "    site = 'PHQ'\n",
    "    \n",
    "if site == 'THD':\n",
    "    sensors1 = 4\n",
    "    path = '/Volumes/hydroProjects/Data/FieldData/pingersites/Steamboat/data/wy'+wypath+'/THD/raw/'\n",
    "    outpath = '/Volumes/hydroProjects/Data/FieldData/pingersites/Steamboat/data/wy2014/THD'\n",
    "    site = 'THD2'\n",
    "    files=glob.glob(path+'/'+site+'_Table1_*.dat') # get all the files from one site\n",
    "    site = 'THD'\n",
    "    \n",
    "if site == 'AFX':\n",
    "    sensors1 = 9\n",
    "    path = '/Volumes/hydroProjects/Data/FieldData/pingersites/AMS/data/as_received/WY'+wypath+'_Ameriflux'\n",
    "    outpath = '/Volumes/hydroProjects/Data/FieldData/pingersites/AMS/data/as_received'\n",
    "    site = 'noah'\n",
    "    files=glob.glob(path+'/*') # get all the files from one site\n",
    "    site = 'AFX'\n",
    "    \n",
    "if site == 'JMZ':\n",
    "    sensors1 = 9\n",
    "    path = '/Volumes/hydroProjects/Data/FieldData/pingersites/CZO/jemez/data/wy'+wypath\n",
    "    outpath = '/Volumes/hydroProjects/Data/FieldData/pingersites/CZO/jemez/'\n",
    "    files = glob.glob(path+'/*')\n",
    "\n",
    "#print 'Data Files Found:'\n",
    "#files\n",
    "\n",
    "print len(files),\"Data Files Found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "USA_cols = ['100','Year_RTM','Day_RTM','Hour_Minute_RTM','Bat_Volts_MIN','AirTmpC_1_AVG','AirTmpF_1_AVG',\n",
    "            'DSDepth_1','AirTmpC_2_AVG','AirTmpF_2_AVG','DSDepth_2','AirTmpC_3_AVG','AirTmpF_3_AVG','DSDepth_3',\n",
    "            'AirTmpC_4_AVG','AirTmpF_4_AVG','DSDepth_4','AirTmpC_5_AVG','AirTmpF_5_AVG','DSDepth_5','AirTmpC_6_AVG',\n",
    "            'AirTmpF_6_AVG','DSDepth_6','AirTmpC_7_AVG','AirTmpF_7_AVG','DSDepth_7','DAirTC_8_AVG','DAirTF_8_AVG','DSDepth_8',\n",
    "            'DAirTC_9_AVG','DAirTF_9_AVG','DSDepth_9','AirTC_10_AVG','AirTF_10_AVG','DSDepth_10']\n",
    "JMZ_cols = ['100','year','doy','hour','volts','airT_C_1','DSDepth_1','echos_1','retries_1','airT_C_2','DSDepth_2','echos_2',\n",
    "            'retries_2','airT_C_3','DSDepth_3','echos_3','retries_3','airT_C_4','DSDepth_4','echos_4','retries_4','airT_C_5',\n",
    "            'DSDepth_5','echos_5','retries_5','airT_C_6','DSDepth_6','echos_6','retries_6','airT_C_7','DSDepth_7','echos_7',\n",
    "            'retries_7','airT_C_8','DSDepth_8','echos_8','retries_8','airT_C_9','DSDepth_9','echos_9','retries_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dtparse(year,doy,time):\n",
    "    if len(str(time)) == 3:\n",
    "        time = '0'+time # add a leading zero\n",
    "        h = int(time[0:2]) # pull out hour\n",
    "        m = int(time[2:4]) # pull out minutes\n",
    "    if len(str(time)) == 4:\n",
    "        h = int(time[0:2]) # pull out hour\n",
    "        m = int(time[2:4]) # pull out minutes\n",
    "        \n",
    "    if h == 24:\n",
    "        doy = int(doy) + 1\n",
    "        h = 0\n",
    "    return pd.datetime.strptime(str(year)+' '+str(doy)+' '+str(h)+' '+str(m),'%Y %j %H %M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a master data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ct = 0\n",
    "dat = pd.DataFrame() # preallocate\n",
    "for fl in files:\n",
    "    if fl[-3:] == 'pcl':\n",
    "        continue # skip pcl data files\n",
    "    if (site == 'ALP') or (site == 'LSA') or (site == 'PHQ') or (site == 'THD'):\n",
    "    \n",
    "        tmp = pd.read_csv(fl, header=True, na_values='NAN', low_memory=False) # load the data\n",
    "        tmp = tmp[2:-1] # remove the two lines at the beginning after the header\n",
    "        tmp.index=pd.DatetimeIndex(tmp.TIMESTAMP)\n",
    "        #print 'data loaded!' \n",
    "        #del tmp['TIMESTAMP']\n",
    "    if (site == 'USA') or (site == 'AFX') or (site == 'JMZ'):\n",
    "        \n",
    "        if (site == 'USA') or (site == 'AFX'):\n",
    "            ncols = USA_cols\n",
    "        if site == 'JMZ':\n",
    "            ncols = JMZ_cols\n",
    "        \n",
    "        tmp = pd.read_csv(fl, skiprows=0, header=False, names=ncols, parse_dates = {'date':[1,2,3]},\n",
    "                          date_parser=dtparse)\n",
    "        tmp.index = pd.DatetimeIndex(tmp.date)\n",
    "        tmp = tmp.convert_objects(convert_numeric=True)\n",
    "        #del tmp['date']\n",
    "\n",
    "    dat = dat.append(tmp)\n",
    "    #print 'data appended'\n",
    "    #del tmp\n",
    "    \n",
    "    #print ct\n",
    "    ct += 1\n",
    "\n",
    "#dat.index = pd.DatetimeIndex(dat.date)\n",
    "#dat = dat.sort_index()\n",
    "#dat = dat.drop_duplicates()\n",
    "#dat = dat.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wy = int(wypath)\n",
    "\n",
    "#dat = dat[str(wy-1)+'-10-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.drop_duplicates(inplace=True) # remove duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'site' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-01f01bac3fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Site: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'site' is not defined"
     ]
    }
   ],
   "source": [
    "print \"Site: \",site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting: DSDepth_1\n",
      "Plotting: DSDepth_2\n",
      "Plotting: DSDepth_3\n",
      "Plotting: DSDepth_4\n",
      "Plotting: DSDepth_5\n",
      "Plotting: DSDepth_6\n",
      "Plotting: DSDepth_7\n",
      "Plotting: DSDepth_8\n",
      "Plotting: DSDepth_9\n",
      "Plotting: DSDepth_10\n"
     ]
    }
   ],
   "source": [
    "if site == 'ALP':\n",
    "    sensors = range(1,sensors1+1)+[13,14]\n",
    "else: \n",
    "    sensors = range(1,sensors1+1)\n",
    "\n",
    "\n",
    "with PdfPages(plotpth+site+'_snowdepth_wy'+wypath+'_'+filedate+'.pdf') as pdf:\n",
    "    for sens in sensors:\n",
    "        \n",
    "        if (site == 'PHQ'):\n",
    "            nameprfx = 'Snowdepth'\n",
    "        else:\n",
    "            nameprfx = 'DSDepth_' # generate sensor name\n",
    "        if (site == 'PHQ') or (site == 'THD'):\n",
    "            date = dat.index.max() # pull the last date of record\n",
    "        else:\n",
    "            date = dat.index.max() # pull the last date of record\n",
    "        \n",
    "        name = nameprfx+str(sens)\n",
    "        plt.figure(figsize = (11,5))\n",
    "        plt.plot(dat.index,dat[name],'.c')\n",
    "        #plt.plot(dat2.index,dat2[name],'k-')\n",
    "        plt.title(site+' Snow Depth: Sensor '+str(sens), fontsize=24)\n",
    "        plt.ylabel('Depth [cm]', fontsize=18)\n",
    "        plt.ylim([-80,400])\n",
    "        plt.xlim(['2014-10-01','2015-08-15'])\n",
    "        plt.axhline(0,c='k')\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        ax.xaxis.set_major_formatter(myFmt)\n",
    "\n",
    "        plt.axvline(date, c='r')\n",
    "        plt.text(datetime.datetime(2014,10,10),550,'Date of Download: '+str(date))\n",
    "\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        print 'Plotting: '+name\n",
    "    \n",
    "    d = pdf.infodict()    \n",
    "    d['Title'] = site+' Snow Depth'\n",
    "    d['Author'] = 'Theodore Barnhart'\n",
    "    d['CreationDate'] = datetime.datetime(2014, 9, 12)\n",
    "    d['ModDate'] = datetime.datetime.today()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
